{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":": MLP for regression problem using Keras - Boston House price.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOYq76SW+X3L35Nq9HZWTSP"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"wANZCoXMW_fL","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"dcb5173d-48a2-47f1-a2ba-7cf1c318820d","executionInfo":{"status":"ok","timestamp":1587147696789,"user_tz":-330,"elapsed":7274,"user":{"displayName":"Akhil K V","photoUrl":"","userId":"17713111322812223260"}}},"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n"," \n","\n","from sklearn.datasets import load_boston\n","\n","import tensorflow as tf\n","from tensorflow import keras\n","\n","\n","bostonData = load_boston()\n","\n","X = bostonData.data\n","y = bostonData.target\n","\n","from sklearn.model_selection import train_test_split\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=42)\n","\n","from sklearn.preprocessing import StandardScaler \n","sc = StandardScaler()\n","\n","sc.fit(X_train)\n","\n","X_train_std = sc.transform(X_train)\n","X_test_std = sc.transform(X_test)\n"," \n","\n","model_MLP = keras.models.Sequential()\n","\n","model_MLP.add(keras.layers.Dense(units=5, activation='relu', input_shape= X_train.shape[1:]))\n","\n","model_MLP.add(keras.layers.Dense(units=1, activation='linear'))\n","\n","model_MLP.summary()\n","\n","model_MLP.compile(loss='mse', optimizer='adam', metrics=['mae'])\n","\n","\n","model_MLP.fit(x=X_train_std, y=y_train, validation_split=0.1, epochs=50, batch_size=16)\n","\n","test_loss, test_accuracy = model_MLP.evaluate(x=X_test_std, y=y_test)\n","\n","print(test_loss, test_accuracy)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense (Dense)                (None, 5)                 70        \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 1)                 6         \n","=================================================================\n","Total params: 76\n","Trainable params: 76\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/50\n","23/23 [==============================] - 0s 8ms/step - loss: 633.1359 - mae: 23.4551 - val_loss: 595.8636 - val_mae: 23.5598\n","Epoch 2/50\n","23/23 [==============================] - 0s 2ms/step - loss: 631.4451 - mae: 23.2979 - val_loss: 589.6460 - val_mae: 23.4151\n","Epoch 3/50\n","23/23 [==============================] - 0s 2ms/step - loss: 623.8899 - mae: 23.1533 - val_loss: 583.9006 - val_mae: 23.2794\n","Epoch 4/50\n","23/23 [==============================] - 0s 2ms/step - loss: 615.2347 - mae: 23.0180 - val_loss: 578.4450 - val_mae: 23.1493\n","Epoch 5/50\n","23/23 [==============================] - 0s 2ms/step - loss: 613.3782 - mae: 22.8873 - val_loss: 573.4119 - val_mae: 23.0290\n","Epoch 6/50\n","23/23 [==============================] - 0s 2ms/step - loss: 606.3322 - mae: 22.7610 - val_loss: 568.3193 - val_mae: 22.9039\n","Epoch 7/50\n","23/23 [==============================] - 0s 2ms/step - loss: 604.2928 - mae: 22.6346 - val_loss: 563.4310 - val_mae: 22.7822\n","Epoch 8/50\n","23/23 [==============================] - 0s 2ms/step - loss: 597.2000 - mae: 22.5115 - val_loss: 558.6561 - val_mae: 22.6640\n","Epoch 9/50\n","23/23 [==============================] - 0s 3ms/step - loss: 590.6898 - mae: 22.3915 - val_loss: 553.9795 - val_mae: 22.5432\n","Epoch 10/50\n","23/23 [==============================] - 0s 3ms/step - loss: 585.4879 - mae: 22.2667 - val_loss: 549.3776 - val_mae: 22.4236\n","Epoch 11/50\n","23/23 [==============================] - 0s 3ms/step - loss: 588.4730 - mae: 22.1428 - val_loss: 544.6262 - val_mae: 22.2972\n","Epoch 12/50\n","23/23 [==============================] - 0s 3ms/step - loss: 577.1161 - mae: 22.0135 - val_loss: 539.9536 - val_mae: 22.1741\n","Epoch 13/50\n","23/23 [==============================] - 0s 2ms/step - loss: 574.8236 - mae: 21.8838 - val_loss: 535.2379 - val_mae: 22.0456\n","Epoch 14/50\n","23/23 [==============================] - 0s 2ms/step - loss: 569.7568 - mae: 21.7540 - val_loss: 530.6281 - val_mae: 21.9177\n","Epoch 15/50\n","23/23 [==============================] - 0s 2ms/step - loss: 570.7188 - mae: 21.6203 - val_loss: 526.0859 - val_mae: 21.7899\n","Epoch 16/50\n","23/23 [==============================] - 0s 2ms/step - loss: 562.8426 - mae: 21.4880 - val_loss: 521.2696 - val_mae: 21.6511\n","Epoch 17/50\n","23/23 [==============================] - 0s 2ms/step - loss: 559.0093 - mae: 21.3475 - val_loss: 516.7130 - val_mae: 21.5174\n","Epoch 18/50\n","23/23 [==============================] - 0s 2ms/step - loss: 554.4015 - mae: 21.2080 - val_loss: 512.1917 - val_mae: 21.3821\n","Epoch 19/50\n","23/23 [==============================] - 0s 2ms/step - loss: 546.9736 - mae: 21.0682 - val_loss: 507.6218 - val_mae: 21.2432\n","Epoch 20/50\n","23/23 [==============================] - 0s 3ms/step - loss: 540.6675 - mae: 20.9236 - val_loss: 503.0661 - val_mae: 21.1023\n","Epoch 21/50\n","23/23 [==============================] - 0s 3ms/step - loss: 538.5345 - mae: 20.7832 - val_loss: 498.5434 - val_mae: 20.9595\n","Epoch 22/50\n","23/23 [==============================] - 0s 2ms/step - loss: 540.1646 - mae: 20.6398 - val_loss: 493.9562 - val_mae: 20.8110\n","Epoch 23/50\n","23/23 [==============================] - 0s 3ms/step - loss: 535.3395 - mae: 20.4968 - val_loss: 489.5966 - val_mae: 20.6684\n","Epoch 24/50\n","23/23 [==============================] - 0s 2ms/step - loss: 532.6202 - mae: 20.3531 - val_loss: 485.2547 - val_mae: 20.5241\n","Epoch 25/50\n","23/23 [==============================] - 0s 3ms/step - loss: 526.2726 - mae: 20.2120 - val_loss: 480.7942 - val_mae: 20.3723\n","Epoch 26/50\n","23/23 [==============================] - 0s 3ms/step - loss: 523.7675 - mae: 20.0691 - val_loss: 476.5871 - val_mae: 20.2366\n","Epoch 27/50\n","23/23 [==============================] - 0s 3ms/step - loss: 518.1636 - mae: 19.9316 - val_loss: 472.3333 - val_mae: 20.1065\n","Epoch 28/50\n","23/23 [==============================] - 0s 3ms/step - loss: 512.3059 - mae: 19.7986 - val_loss: 468.1771 - val_mae: 19.9771\n","Epoch 29/50\n","23/23 [==============================] - 0s 3ms/step - loss: 514.9911 - mae: 19.6727 - val_loss: 464.1368 - val_mae: 19.8485\n","Epoch 30/50\n","23/23 [==============================] - 0s 3ms/step - loss: 507.5805 - mae: 19.5554 - val_loss: 459.9806 - val_mae: 19.7132\n","Epoch 31/50\n","23/23 [==============================] - 0s 3ms/step - loss: 501.0264 - mae: 19.4389 - val_loss: 456.1841 - val_mae: 19.5879\n","Epoch 32/50\n","23/23 [==============================] - 0s 2ms/step - loss: 504.7627 - mae: 19.3208 - val_loss: 452.3315 - val_mae: 19.4581\n","Epoch 33/50\n","23/23 [==============================] - 0s 2ms/step - loss: 498.7929 - mae: 19.2095 - val_loss: 448.2986 - val_mae: 19.3178\n","Epoch 34/50\n","23/23 [==============================] - 0s 2ms/step - loss: 495.2691 - mae: 19.0943 - val_loss: 444.7881 - val_mae: 19.1960\n","Epoch 35/50\n","23/23 [==============================] - 0s 3ms/step - loss: 488.8481 - mae: 18.9889 - val_loss: 441.1751 - val_mae: 19.0682\n","Epoch 36/50\n","23/23 [==============================] - 0s 3ms/step - loss: 489.8664 - mae: 18.8813 - val_loss: 437.6750 - val_mae: 18.9421\n","Epoch 37/50\n","23/23 [==============================] - 0s 3ms/step - loss: 483.5209 - mae: 18.7785 - val_loss: 434.2717 - val_mae: 18.8181\n","Epoch 38/50\n","23/23 [==============================] - 0s 3ms/step - loss: 481.5912 - mae: 18.6794 - val_loss: 430.9553 - val_mae: 18.6957\n","Epoch 39/50\n","23/23 [==============================] - 0s 2ms/step - loss: 478.1134 - mae: 18.5751 - val_loss: 427.6661 - val_mae: 18.5723\n","Epoch 40/50\n","23/23 [==============================] - 0s 3ms/step - loss: 476.2642 - mae: 18.4747 - val_loss: 424.1260 - val_mae: 18.4434\n","Epoch 41/50\n","23/23 [==============================] - 0s 2ms/step - loss: 472.6022 - mae: 18.3751 - val_loss: 420.6581 - val_mae: 18.3219\n","Epoch 42/50\n","23/23 [==============================] - 0s 2ms/step - loss: 470.6754 - mae: 18.2790 - val_loss: 416.8502 - val_mae: 18.1895\n","Epoch 43/50\n","23/23 [==============================] - 0s 2ms/step - loss: 461.8135 - mae: 18.1786 - val_loss: 413.4563 - val_mae: 18.0744\n","Epoch 44/50\n","23/23 [==============================] - 0s 3ms/step - loss: 465.3041 - mae: 18.0843 - val_loss: 410.0115 - val_mae: 17.9520\n","Epoch 45/50\n","23/23 [==============================] - 0s 3ms/step - loss: 458.0478 - mae: 17.9909 - val_loss: 406.4207 - val_mae: 17.8306\n","Epoch 46/50\n","23/23 [==============================] - 0s 2ms/step - loss: 455.7873 - mae: 17.8958 - val_loss: 402.7616 - val_mae: 17.7043\n","Epoch 47/50\n","23/23 [==============================] - 0s 3ms/step - loss: 454.6828 - mae: 17.7986 - val_loss: 398.9259 - val_mae: 17.5767\n","Epoch 48/50\n","23/23 [==============================] - 0s 3ms/step - loss: 443.9689 - mae: 17.6967 - val_loss: 394.9196 - val_mae: 17.4520\n","Epoch 49/50\n","23/23 [==============================] - 0s 3ms/step - loss: 440.5340 - mae: 17.5835 - val_loss: 389.9970 - val_mae: 17.3102\n","Epoch 50/50\n","23/23 [==============================] - 0s 3ms/step - loss: 432.0106 - mae: 17.4435 - val_loss: 383.6367 - val_mae: 17.1386\n","4/4 [==============================] - 0s 2ms/step - loss: 372.2592 - mae: 15.9948\n","372.2591552734375 15.994836807250977\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"F1-7RmPWXy4m","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}