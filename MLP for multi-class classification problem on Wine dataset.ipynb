{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"MLP for multi-class classification problem on Wine dataset.ipynb","provenance":[],"authorship_tag":"ABX9TyPUKIc4mZ2e19Fi+T4kq6kj"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"Lwvs1YA_YMUz","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"1853dfb1-e83b-4ed9-ed5c-2fa5438c115a","executionInfo":{"status":"ok","timestamp":1587147930240,"user_tz":-330,"elapsed":7194,"user":{"displayName":"Akhil K V","photoUrl":"","userId":"17713111322812223260"}}},"source":["import numpy as np \n","import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","from sklearn.datasets import load_wine\n"," \n","import tensorflow as tf\n","from tensorflow import keras\n","\n","wineData = load_wine()\n","\n","\n","X = wineData.data\n","y = wineData.target\n","\n","\n","from sklearn.model_selection import train_test_split\n","\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,\n","stratify=y, random_state=42)\n","\n","from sklearn.preprocessing import StandardScaler\n","sc = StandardScaler()\n","\n","sc.fit(X_train)\n","\n","X_train_std = sc.transform(X_train)\n","X_test_std = sc.transform(X_test)\n"," \n","\n","model_MLP = keras.models.Sequential()\n","\n","model_MLP.add(keras.layers.Dense(units=5, activation='relu',input_shape= X_train.shape[1:]))\n","\n","model_MLP.add(keras.layers.Dense(units=3, activation='softmax'))\n","\n","\n","model_MLP.summary()\n","\n","model_MLP.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","\n","model_MLP.fit(x=X_train_std, y=y_train, validation_split=0.1, epochs=50, batch_size=16)\n","\n","test_loss, test_accuracy = model_MLP.evaluate(x=X_test_std, y=y_test)\n","\n","\n","print(test_loss, test_accuracy)\n"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense (Dense)                (None, 5)                 70        \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 3)                 18        \n","=================================================================\n","Total params: 88\n","Trainable params: 88\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/50\n","8/8 [==============================] - 0s 24ms/step - loss: 1.3377 - accuracy: 0.3071 - val_loss: 1.1098 - val_accuracy: 0.3333\n","Epoch 2/50\n","8/8 [==============================] - 0s 7ms/step - loss: 1.2731 - accuracy: 0.3307 - val_loss: 1.0605 - val_accuracy: 0.4000\n","Epoch 3/50\n","8/8 [==============================] - 0s 5ms/step - loss: 1.2178 - accuracy: 0.3307 - val_loss: 1.0145 - val_accuracy: 0.4000\n","Epoch 4/50\n","8/8 [==============================] - 0s 6ms/step - loss: 1.1679 - accuracy: 0.3386 - val_loss: 0.9723 - val_accuracy: 0.4667\n","Epoch 5/50\n","8/8 [==============================] - 0s 6ms/step - loss: 1.1184 - accuracy: 0.3701 - val_loss: 0.9332 - val_accuracy: 0.4667\n","Epoch 6/50\n","8/8 [==============================] - 0s 7ms/step - loss: 1.0778 - accuracy: 0.3937 - val_loss: 0.8956 - val_accuracy: 0.5333\n","Epoch 7/50\n","8/8 [==============================] - 0s 6ms/step - loss: 1.0382 - accuracy: 0.4173 - val_loss: 0.8608 - val_accuracy: 0.6667\n","Epoch 8/50\n","8/8 [==============================] - 0s 5ms/step - loss: 1.0017 - accuracy: 0.4331 - val_loss: 0.8280 - val_accuracy: 0.7333\n","Epoch 9/50\n","8/8 [==============================] - 0s 5ms/step - loss: 0.9700 - accuracy: 0.4409 - val_loss: 0.7971 - val_accuracy: 0.7333\n","Epoch 10/50\n","8/8 [==============================] - 0s 5ms/step - loss: 0.9409 - accuracy: 0.4646 - val_loss: 0.7664 - val_accuracy: 0.7333\n","Epoch 11/50\n","8/8 [==============================] - 0s 6ms/step - loss: 0.9154 - accuracy: 0.4803 - val_loss: 0.7375 - val_accuracy: 0.7333\n","Epoch 12/50\n","8/8 [==============================] - 0s 5ms/step - loss: 0.8913 - accuracy: 0.5197 - val_loss: 0.7110 - val_accuracy: 0.7333\n","Epoch 13/50\n","8/8 [==============================] - 0s 5ms/step - loss: 0.8694 - accuracy: 0.5276 - val_loss: 0.6858 - val_accuracy: 0.7333\n","Epoch 14/50\n","8/8 [==============================] - 0s 5ms/step - loss: 0.8478 - accuracy: 0.5669 - val_loss: 0.6610 - val_accuracy: 0.7333\n","Epoch 15/50\n","8/8 [==============================] - 0s 6ms/step - loss: 0.8275 - accuracy: 0.5748 - val_loss: 0.6364 - val_accuracy: 0.8000\n","Epoch 16/50\n","8/8 [==============================] - 0s 5ms/step - loss: 0.8065 - accuracy: 0.5984 - val_loss: 0.6137 - val_accuracy: 0.8000\n","Epoch 17/50\n","8/8 [==============================] - 0s 5ms/step - loss: 0.7891 - accuracy: 0.5984 - val_loss: 0.5927 - val_accuracy: 0.8000\n","Epoch 18/50\n","8/8 [==============================] - 0s 5ms/step - loss: 0.7711 - accuracy: 0.6378 - val_loss: 0.5732 - val_accuracy: 0.8667\n","Epoch 19/50\n","8/8 [==============================] - 0s 5ms/step - loss: 0.7539 - accuracy: 0.6614 - val_loss: 0.5535 - val_accuracy: 0.8667\n","Epoch 20/50\n","8/8 [==============================] - 0s 6ms/step - loss: 0.7375 - accuracy: 0.6693 - val_loss: 0.5345 - val_accuracy: 0.8667\n","Epoch 21/50\n","8/8 [==============================] - 0s 5ms/step - loss: 0.7212 - accuracy: 0.6614 - val_loss: 0.5167 - val_accuracy: 0.9333\n","Epoch 22/50\n","8/8 [==============================] - 0s 5ms/step - loss: 0.7068 - accuracy: 0.6614 - val_loss: 0.5002 - val_accuracy: 0.9333\n","Epoch 23/50\n","8/8 [==============================] - 0s 5ms/step - loss: 0.6940 - accuracy: 0.6850 - val_loss: 0.4837 - val_accuracy: 0.9333\n","Epoch 24/50\n","8/8 [==============================] - 0s 6ms/step - loss: 0.6796 - accuracy: 0.6850 - val_loss: 0.4681 - val_accuracy: 0.9333\n","Epoch 25/50\n","8/8 [==============================] - 0s 5ms/step - loss: 0.6643 - accuracy: 0.7165 - val_loss: 0.4527 - val_accuracy: 0.9333\n","Epoch 26/50\n","8/8 [==============================] - 0s 6ms/step - loss: 0.6516 - accuracy: 0.7244 - val_loss: 0.4380 - val_accuracy: 0.9333\n","Epoch 27/50\n","8/8 [==============================] - 0s 5ms/step - loss: 0.6393 - accuracy: 0.7323 - val_loss: 0.4225 - val_accuracy: 0.9333\n","Epoch 28/50\n","8/8 [==============================] - 0s 5ms/step - loss: 0.6251 - accuracy: 0.7480 - val_loss: 0.4082 - val_accuracy: 1.0000\n","Epoch 29/50\n","8/8 [==============================] - 0s 5ms/step - loss: 0.6110 - accuracy: 0.7638 - val_loss: 0.3938 - val_accuracy: 1.0000\n","Epoch 30/50\n","8/8 [==============================] - 0s 6ms/step - loss: 0.5989 - accuracy: 0.7874 - val_loss: 0.3797 - val_accuracy: 1.0000\n","Epoch 31/50\n","8/8 [==============================] - 0s 5ms/step - loss: 0.5886 - accuracy: 0.8031 - val_loss: 0.3665 - val_accuracy: 1.0000\n","Epoch 32/50\n","8/8 [==============================] - 0s 5ms/step - loss: 0.5768 - accuracy: 0.8110 - val_loss: 0.3538 - val_accuracy: 1.0000\n","Epoch 33/50\n","8/8 [==============================] - 0s 6ms/step - loss: 0.5635 - accuracy: 0.8346 - val_loss: 0.3418 - val_accuracy: 1.0000\n","Epoch 34/50\n","8/8 [==============================] - 0s 7ms/step - loss: 0.5520 - accuracy: 0.8661 - val_loss: 0.3299 - val_accuracy: 1.0000\n","Epoch 35/50\n","8/8 [==============================] - 0s 6ms/step - loss: 0.5403 - accuracy: 0.8661 - val_loss: 0.3185 - val_accuracy: 1.0000\n","Epoch 36/50\n","8/8 [==============================] - 0s 6ms/step - loss: 0.5283 - accuracy: 0.8661 - val_loss: 0.3076 - val_accuracy: 1.0000\n","Epoch 37/50\n","8/8 [==============================] - 0s 5ms/step - loss: 0.5167 - accuracy: 0.8661 - val_loss: 0.2969 - val_accuracy: 1.0000\n","Epoch 38/50\n","8/8 [==============================] - 0s 5ms/step - loss: 0.5052 - accuracy: 0.8898 - val_loss: 0.2863 - val_accuracy: 1.0000\n","Epoch 39/50\n","8/8 [==============================] - 0s 5ms/step - loss: 0.4941 - accuracy: 0.8898 - val_loss: 0.2760 - val_accuracy: 1.0000\n","Epoch 40/50\n","8/8 [==============================] - 0s 6ms/step - loss: 0.4829 - accuracy: 0.8976 - val_loss: 0.2661 - val_accuracy: 1.0000\n","Epoch 41/50\n","8/8 [==============================] - 0s 7ms/step - loss: 0.4718 - accuracy: 0.8976 - val_loss: 0.2567 - val_accuracy: 1.0000\n","Epoch 42/50\n","8/8 [==============================] - 0s 6ms/step - loss: 0.4613 - accuracy: 0.8976 - val_loss: 0.2478 - val_accuracy: 1.0000\n","Epoch 43/50\n","8/8 [==============================] - 0s 6ms/step - loss: 0.4504 - accuracy: 0.9134 - val_loss: 0.2391 - val_accuracy: 1.0000\n","Epoch 44/50\n","8/8 [==============================] - 0s 5ms/step - loss: 0.4397 - accuracy: 0.9213 - val_loss: 0.2303 - val_accuracy: 1.0000\n","Epoch 45/50\n","8/8 [==============================] - 0s 5ms/step - loss: 0.4295 - accuracy: 0.9213 - val_loss: 0.2223 - val_accuracy: 1.0000\n","Epoch 46/50\n","8/8 [==============================] - 0s 5ms/step - loss: 0.4186 - accuracy: 0.9291 - val_loss: 0.2144 - val_accuracy: 1.0000\n","Epoch 47/50\n","8/8 [==============================] - 0s 5ms/step - loss: 0.4085 - accuracy: 0.9370 - val_loss: 0.2070 - val_accuracy: 1.0000\n","Epoch 48/50\n","8/8 [==============================] - 0s 5ms/step - loss: 0.3992 - accuracy: 0.9370 - val_loss: 0.1996 - val_accuracy: 1.0000\n","Epoch 49/50\n","8/8 [==============================] - 0s 6ms/step - loss: 0.3879 - accuracy: 0.9370 - val_loss: 0.1925 - val_accuracy: 1.0000\n","Epoch 50/50\n","8/8 [==============================] - 0s 5ms/step - loss: 0.3782 - accuracy: 0.9370 - val_loss: 0.1857 - val_accuracy: 1.0000\n","2/2 [==============================] - 0s 3ms/step - loss: 0.2295 - accuracy: 0.8611\n","0.22948959469795227 0.8611111044883728\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"KuALMMWNYfLu","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}